M_all = do.call(cbind, M)
S = length(M)
S_assign = c()
for (s in 1:S) {
S_assign = c(S_assign, rep(s, ncol(M[[s]])))
}
dat = list(
M = M_all,
N = N,
K = nrow(M_all),
G = ncol(M_all),
S = S,
S_assign = S_assign
)
model_text <- write_normal_exponential_multi_jags(
alpha, beta, lambda_p, lambda_e, a, b
)
lambda_p
prior_for_lists <- ""
for (k in 1:K) {
prior_for_lists = paste0(
prior_for_lists,
"\nalpha[", k, "] <- ", alpha[k],
"\nbeta[", k, "] <- ", beta[k]
)
for (n in 1:N) {
prior_for_lists = paste0(
prior_for_lists,
"\nlambda_p[",k,",",n,"] <- ", lambda_p[k,n]
)
}
}
for (n in 1:N) {
for (g in 1:G) {
prior_for_lists = paste0(
prior_for_lists,
"\nlambda_e[",n,",",g,"] <-", lambda_e[n,g]
)
}
}
G
M_all = do.call(cbind, M)
S = length(M)
S_assign = c()
for (s in 1:S) {
S_assign = c(S_assign, rep(s, ncol(M[[s]])))
}
dat = list(
M = M_all,
N = N,
K = nrow(M_all),
G = ncol(M_all),
S = S,
S_assign = S_assign
)
G = ncol(M_all)
prior_for_lists <- ""
for (k in 1:dat$K) {
prior_for_lists = paste0(
prior_for_lists,
"\nalpha[", k, "] <- ", alpha[k],
"\nbeta[", k, "] <- ", beta[k]
)
for (n in 1:dat$N) {
prior_for_lists = paste0(
prior_for_lists,
"\nlambda_p[",k,",",n,"] <- ", lambda_p[k,n]
)
}
}
for (n in 1:dat$N) {
for (g in 1:dat$G) {
prior_for_lists = paste0(
prior_for_lists,
"\nlambda_e[",n,",",g,"] <-", lambda_e[n,g]
)
}
}
prior_for_lists
print(prior_for_lists)
cat(prior_for_lists)
paste0("model
{
# likelihood
for (k in 1:K) {
for (g in 1:G) {
M[k,g] ~ dnorm(inprod(P[k,], E[,g] * A[S_assign[g],]), sigmasq[k])
Mhat[k,g] <- max(inprod(P[k,], E[,g] * A[S_assign[g],]), 1)
loglikelihood[k,g] <- (2*", pi, "*sigmasq[k])^(-1/2) * ",
exp(1), "^(-(1/(2*sigmasq[k]))*(M[k,g] - Mhat[k,g])^2)
}
}
Log_Likelihood <- sum(loglikelihood)
KL_Div <- sum(M * log(M / Mhat) - M + Mhat)
RMSE <- sqrt(mean((M - Mhat)^2))
#priors
for (s in 1:S) {
for (n in 1:N) {
A[s,n] ~ dbin(q[s,n], 1)
q[s,n] ~ dbeta(a, b)
}
}
for (k in 1:K) {
precision[k] ~ dgamma(alpha[k], beta[k])
sigmasq[k] <- 1/precision[k]
}
for (k in 1:K) {
for (n in 1:N) {
P[k,n] ~ dexp(lambda_p[k,n])
}
}
for (n in 1:N){
for (g in 1:G){
E[n,g] ~ dexp(lambda_e[n,g])
}
}",
prior_for_lists
,"
a <- ", a, "
b <- ", b, "
}
")
source("~/Desktop/github/jennalandy/bayesNMF/R/normal_exponential_multi.R", echo=TRUE)
{
source("tests/testthat/setup_multistudy_poisson.R")
N = 5
niters = 1000
burn_in = round(2*niters/3)
n.chains = 1
n.adapt = 500
inits = NULL
lambda_p = matrix(sqrt(N/100), nrow = dim(M[[1]])[1], ncol = N)
lambda_e = matrix( sqrt(N/100), nrow = N, ncol = sum(sapply(M, ncol)))
alpha = rep(0.1, dim(M[[1]])[1])
beta = rep(2, dim(M[[1]])[1])
a = 0.8
b = 0.8
true_P = NULL
verbose = TRUE
plotting = TRUE
return_samples = TRUE
}
M_all = do.call(cbind, M)
S = length(M)
S_assign = c()
for (s in 1:S) {
S_assign = c(S_assign, rep(s, ncol(M[[s]])))
}
dat = list(
M = M_all,
N = N,
K = nrow(M_all),
G = ncol(M_all),
S = S,
S_assign = S_assign
)
model_text <- write_normal_exponential_multi_jags(
alpha, beta, lambda_p, lambda_e, a, b
)
model_text <- write_normal_exponential_multi_jags(
alpha, beta, lambda_p, lambda_e, a, b, dat
)
model_textConnection <- textConnection(model_text)
# rjags::set.factory("mix::TemperedMix", "sampler", TRUE)
if (is.null(inits)) {
jags.m <- rjags::jags.model(
file = model_textConnection,
data = dat,
n.chains = n.chains,
n.adapt = n.adapt,
quiet = !verbose
)
} else {
jags.m <- rjags::jags.model(
file = model_textConnection,
data = dat,
n.chains = n.chains,
n.adapt = n.adapt,
quiet = !verbose,
inits = inits
)
}
close(model_textConnection)
params = c("P", "E", "sigmasq", "A",
"Log_Likelihood", "KL_Div", "RMSE")
# burn in - samples not recorded
if (verbose) {cat("\nBurn-in Samples\n\n")}
# samples from posterior - samples are recorded
if (verbose) {cat("\nRecorded Samples\n\n")}
samples <- rjags::coda.samples(
jags.m,
params,
n.iter = niters,
quiet = !verbose
)
samples_df = do.call(rbind.data.frame, samples)
A.map <- extract_mode_matrix(samples_df, "A")
A.map_str <- paste(melt(A.map)[,'value'], collapse = '')
A.map_inds <- samples_df %>%
select(starts_with("A")) %>%
apply(., 1, function(row) {paste(row, collapse = '')}) %>%
str_which(A.map_str)
P.map <- extract_mean_matrix(samples_df[A.map_inds,], "P")
E.map <- extract_mean_matrix(samples_df[A.map_inds,], "E")
sigmasq.map <- extract_mean_vector(samples_df[A.map_inds,], "sigmasq")
MAP = list(
A = A.map,
P = P.map,
E = E.map,
sigmasq = sigmasq.map
)
A.map
A
prefix = "A"
samples_df %>%
select(starts_with(prefix)) %>%
group_by_all() %>%
summarize(count = n(), .groups = 'keep')
samples_df %>%
select(starts_with(prefix))
samples_df %>%
select(starts_with(prefix)) %>% colMeans()
samples_df %>%
select(starts_with("prefix"))
model_text <- write_normal_exponential_multi_jags(
alpha, beta, lambda_p, lambda_e, a, b, dat
)
model_textConnection <- textConnection(model_text)
# rjags::set.factory("mix::TemperedMix", "sampler", TRUE)
if (is.null(inits)) {
jags.m <- rjags::jags.model(
file = model_textConnection,
data = dat,
n.chains = n.chains,
n.adapt = n.adapt,
quiet = !verbose
)
} else {
jags.m <- rjags::jags.model(
file = model_textConnection,
data = dat,
n.chains = n.chains,
n.adapt = n.adapt,
quiet = !verbose,
inits = inits
)
}
close(model_textConnection)
params = c("P", "E", "sigmasq", "A", "q",
"Log_Likelihood", "KL_Div", "RMSE")
# burn in - samples not recorded
if (verbose) {cat("\nBurn-in Samples\n\n")}
# samples from posterior - samples are recorded
if (verbose) {cat("\nRecorded Samples\n\n")}
samples <- rjags::coda.samples(
jags.m,
params,
n.iter = niters,
quiet = !verbose
)
samples_df = do.call(rbind.data.frame, samples)
A.map <- extract_mode_matrix(samples_df, "A")
A.map_str <- paste(melt(A.map)[,'value'], collapse = '')
A.map_inds <- samples_df %>%
select(starts_with("A")) %>%
apply(., 1, function(row) {paste(row, collapse = '')}) %>%
str_which(A.map_str)
P.map <- extract_mean_matrix(samples_df[A.map_inds,], "P")
E.map <- extract_mean_matrix(samples_df[A.map_inds,], "E")
sigmasq.map <- extract_mean_vector(samples_df[A.map_inds,], "sigmasq")
MAP = list(
A = A.map,
P = P.map,
E = E.map,
sigmasq = sigmasq.map
)
samples_df %>%
select(starts_with("q"))
samples_df %>%
select(starts_with("A"))
samples_df %>%
select(starts_with("q"))
source("~/Desktop/github/jennalandy/bayesNMF/R/normal_exponential_multi.R", echo=TRUE)
{
source("tests/testthat/setup_multistudy_poisson.R")
N = 5
niters = 1000
burn_in = round(2*niters/3)
n.chains = 1
n.adapt = 500
inits = NULL
lambda_p = matrix(sqrt(N/100), nrow = dim(M[[1]])[1], ncol = N)
lambda_e = matrix( sqrt(N/100), nrow = N, ncol = sum(sapply(M, ncol)))
alpha = rep(0.1, dim(M[[1]])[1])
beta = rep(2, dim(M[[1]])[1])
a = 0.8
b = 0.8
true_P = NULL
verbose = TRUE
plotting = TRUE
return_samples = TRUE
}
M_all = do.call(cbind, M)
S = length(M)
S_assign = c()
for (s in 1:S) {
S_assign = c(S_assign, rep(s, ncol(M[[s]])))
}
dat = list(
M = M_all,
N = N,
K = nrow(M_all),
G = ncol(M_all),
S = S,
S_assign = S_assign
)
model_text <- write_normal_exponential_multi_jags(
alpha, beta, lambda_p, lambda_e, a, b, dat
)
model_textConnection <- textConnection(model_text)
# rjags::set.factory("mix::TemperedMix", "sampler", TRUE)
if (is.null(inits)) {
jags.m <- rjags::jags.model(
file = model_textConnection,
data = dat,
n.chains = n.chains,
n.adapt = n.adapt,
quiet = !verbose
)
} else {
jags.m <- rjags::jags.model(
file = model_textConnection,
data = dat,
n.chains = n.chains,
n.adapt = n.adapt,
quiet = !verbose,
inits = inits
)
}
close(model_textConnection)
params = c("P", "E", "sigmasq", "A", "q",
"Log_Likelihood", "KL_Div", "RMSE")
# burn in - samples not recorded
if (verbose) {cat("\nBurn-in Samples\n\n")}
# samples from posterior - samples are recorded
if (verbose) {cat("\nRecorded Samples\n\n")}
samples <- rjags::coda.samples(
jags.m,
params,
n.iter = niters,
quiet = !verbose
)
samples_df = do.call(rbind.data.frame, samples)
samples_df %>%
select(starts_with("A"))
samples_df %>%
select(starts_with("q"))
jags.m
?update
rjags::set.factory("mix::TemperedMix", "sampler", TRUE)
if (is.null(inits)) {
jags.m <- rjags::jags.model(
file = model_textConnection,
data = dat,
n.chains = n.chains,
n.adapt = n.adapt,
quiet = !verbose
)
} else {
jags.m <- rjags::jags.model(
file = model_textConnection,
data = dat,
n.chains = n.chains,
n.adapt = n.adapt,
quiet = !verbose,
inits = inits
)
}
model_text <- write_normal_exponential_multi_jags(
alpha, beta, lambda_p, lambda_e, a, b, dat
)
model_textConnection <- textConnection(model_text)
rjags::set.factory("mix::TemperedMix", "sampler", TRUE)
if (is.null(inits)) {
jags.m <- rjags::jags.model(
file = model_textConnection,
data = dat,
n.chains = n.chains,
n.adapt = n.adapt,
quiet = !verbose
)
} else {
jags.m <- rjags::jags.model(
file = model_textConnection,
data = dat,
n.chains = n.chains,
n.adapt = n.adapt,
quiet = !verbose,
inits = inits
)
}
close(model_textConnection)
params = c("P", "E", "sigmasq", "A", "q",
"Log_Likelihood", "KL_Div", "RMSE")
# burn in - samples not recorded
if (verbose) {cat("\nBurn-in Samples\n\n")}
# samples from posterior - samples are recorded
if (verbose) {cat("\nRecorded Samples\n\n")}
samples <- rjags::coda.samples(
jags.m,
params,
n.iter = niters,
quiet = !verbose
)
samples_df = do.call(rbind.data.frame, samples)
A.map <- extract_mode_matrix(samples_df, "A")
A.map_str <- paste(melt(A.map)[,'value'], collapse = '')
A.map_inds <- samples_df %>%
select(starts_with("A")) %>%
apply(., 1, function(row) {paste(row, collapse = '')}) %>%
str_which(A.map_str)
A.map
samples_df %>%
select(starts_with("A"))
{
source("tests/testthat/setup_multistudy_poisson.R")
N = 5
niters = 1000
burn_in = round(2*niters/3)
n.chains = 1
n.adapt = 1000
inits = NULL
lambda_p = matrix(sqrt(N/100), nrow = dim(M[[1]])[1], ncol = N)
lambda_e = matrix( sqrt(N/100), nrow = N, ncol = sum(sapply(M, ncol)))
alpha = rep(0.1, dim(M[[1]])[1])
beta = rep(2, dim(M[[1]])[1])
a = 0.8
b = 0.8
true_P = NULL
verbose = TRUE
plotting = TRUE
return_samples = TRUE
}
M_all = do.call(cbind, M)
S = length(M)
S_assign = c()
for (s in 1:S) {
S_assign = c(S_assign, rep(s, ncol(M[[s]])))
}
dat = list(
M = M_all,
N = N,
K = nrow(M_all),
G = ncol(M_all),
S = S,
S_assign = S_assign
)
model_text <- write_normal_exponential_multi_jags(
alpha, beta, lambda_p, lambda_e, a, b, dat
)
model_textConnection <- textConnection(model_text)
rjags::set.factory("mix::TemperedMix", "sampler", TRUE)
if (is.null(inits)) {
jags.m <- rjags::jags.model(
file = model_textConnection,
data = dat,
n.chains = n.chains,
n.adapt = n.adapt,
quiet = !verbose
)
} else {
jags.m <- rjags::jags.model(
file = model_textConnection,
data = dat,
n.chains = n.chains,
n.adapt = n.adapt,
quiet = !verbose,
inits = inits
)
}
close(model_textConnection)
params = c("P", "E", "sigmasq", "A", "q",
"Log_Likelihood", "KL_Div", "RMSE")
# burn in - samples not recorded
if (verbose) {cat("\nBurn-in Samples\n\n")}
# samples from posterior - samples are recorded
if (verbose) {cat("\nRecorded Samples\n\n")}
samples <- rjags::coda.samples(
jags.m,
params,
n.iter = niters,
quiet = !verbose
)
samples_df = do.call(rbind.data.frame, samples)
A.map <- extract_mode_matrix(samples_df, "A")
A.map_str <- paste(melt(A.map)[,'value'], collapse = '')
A.map_inds <- samples_df %>%
select(starts_with("A")) %>%
apply(., 1, function(row) {paste(row, collapse = '')}) %>%
str_which(A.map_str)
P.map <- extract_mean_matrix(samples_df[A.map_inds,], "P")
samples_df %>%
select(starts_with("A"))
source("~/Desktop/github/jennalandy/bayesNMF/tests/testthat/setup_normal.R", echo=TRUE)
hist(M)
hist(colSums(M))
source("~/Desktop/github/jennalandy/bayesNMF/tests/testthat/setup_normal_sparse.R", echo=TRUE)
hist(colSums(M))
source("~/Desktop/github/jennalandy/bayesNMF/tests/testthat/setup_poisson.R", echo=TRUE)
hist(colSums(M))
source("~/Desktop/github/jennalandy/bayesNMF/tests/testthat/setup_poisson_sparse.R", echo=TRUE)
hist(colSums(M))
